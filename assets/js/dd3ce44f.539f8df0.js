"use strict";(self.webpackChunknewdocs=self.webpackChunknewdocs||[]).push([[2932],{8725:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>u,contentTitle:()=>i,default:()=>m,frontMatter:()=>d,metadata:()=>c,toc:()=>p});var a=t(4848),r=t(8453),s=t(9489),o=t(7227),l=t(94);const d={sidebar_label:"Multimodal vector search",filename:"multimodal_vector_search.md"},i="Multimodal vector search",c={id:"use_cases/multimodal_vector_search",title:"multimodal_vector_search",description:"Configure your production system",source:"@site/content/use_cases/multimodal_vector_search.md",sourceDirName:"use_cases",slug:"/use_cases/multimodal_vector_search",permalink:"/docs/use_cases/multimodal_vector_search",draft:!1,unlisted:!1,editUrl:"https://github.com/SuperDuperDB/superduperdb/blob/main/docs/hr/content/use_cases/multimodal_vector_search.md",tags:[],version:"current",frontMatter:{sidebar_label:"Multimodal vector search",filename:"multimodal_vector_search.md"},sidebar:"tutorialSidebar",previous:{title:"Fine tune LLM on database",permalink:"/docs/use_cases/fine_tune_llm_on_database"},next:{title:"Retrieval augmented generation",permalink:"/docs/use_cases/retrieval_augmented_generation"}},u={},p=[{value:"Configure your production system",id:"configure-your-production-system",level:2},{value:"Start your cluster",id:"start-your-cluster",level:2},{value:"Connect to SuperDuperDB",id:"connect-to-superduperdb",level:2},{value:"Get useful sample data",id:"get-useful-sample-data",level:2},{value:"Create datatype",id:"create-datatype",level:2},{value:"Setup tables or collections",id:"setup-tables-or-collections",level:2},{value:"Insert data",id:"insert-data",level:2},{value:"Define the embedding model datatype",id:"define-the-embedding-model-datatype",level:4},{value:"Build simple select queries",id:"build-simple-select-queries",level:2},{value:"Create Model Output Type",id:"create-model-output-type",level:2},{value:"Apply a chunker for search",id:"apply-a-chunker-for-search",level:2},{value:"Build multimodal embedding models",id:"build-multimodal-embedding-models",level:2},{value:"Select outputs of upstream listener",id:"select-outputs-of-upstream-listener",level:2},{value:"Create vector-index",id:"create-vector-index",level:2},{value:"Perform a vector search",id:"perform-a-vector-search",level:2},{value:"Visualize Results",id:"visualize-results",level:2},{value:"Check the system stays updated",id:"check-the-system-stays-updated",level:2}];function h(e){const n={a:"a",admonition:"admonition",code:"code",em:"em",h1:"h1",h2:"h2",h4:"h4",p:"p",pre:"pre",strong:"strong",...(0,r.R)(),...e.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(n.h1,{id:"multimodal-vector-search",children:"Multimodal vector search"}),"\n",(0,a.jsx)(n.h2,{id:"configure-your-production-system",children:"Configure your production system"}),"\n",(0,a.jsx)(n.admonition,{type:"note",children:(0,a.jsx)(n.p,{children:'If you would like to use the production features\nof SuperDuperDB, then you should set the relevant\nconnections and configurations in a configuration\nfile. Otherwise you are welcome to use "development" mode\nto get going with SuperDuperDB quickly.'})}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"import os\n\nos.makedirs('.superduperdb', exist_ok=True)\nos.environ['SUPERDUPERDB_CONFIG'] = '.superduperdb/config.yaml'\n"})}),"\n",(0,a.jsxs)(s.A,{children:[(0,a.jsx)(o.A,{value:"MongoDB Community",label:"MongoDB Community",default:!0,children:(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"CFG = '''\ndata_backend: mongodb://127.0.0.1:27017/documents\nartifact_store: filesystem://./artifact_store\ncluster:\n  cdc:\n    strategy: null\n    uri: ray://127.0.0.1:20000\n  compute:\n    uri: ray://127.0.0.1:10001\n  vector_search:\n    backfill_batch_size: 100\n    type: in_memory\n    uri: http://127.0.0.1:21000\n'''        \n"})})}),(0,a.jsx)(o.A,{value:"MongoDB Atlas",label:"MongoDB Atlas",default:!0,children:(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"CFG = '''\nartifact_store: filesystem://<path-to-artifact-store>\ncluster: \n    compute: ray://<ray-host>\n    cdc:    \n        uri: http://<cdc-host>:<cdc-port>\n    vector_search:\n        uri: http://<vector-search-host>:<vector-search-port>\n        type: native\ndatabackend: mongodb+srv://<user>:<password>@<mongo-host>:27017/documents\n'''        \n"})})}),(0,a.jsx)(o.A,{value:"SQLite",label:"SQLite",default:!0,children:(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"CFG = '''\nartifact_store: filesystem://<path-to-artifact-store>\ncluster: \n    compute: ray://<ray-host>\n    cdc:    \n        uri: http://<cdc-host>:<cdc-port>\n    vector_search:\n        uri: http://<vector-search-host>:<vector-search-port>\ndatabackend: sqlite://<path-to-db>.db\n'''        \n"})})}),(0,a.jsx)(o.A,{value:"MySQL",label:"MySQL",default:!0,children:(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"CFG = '''\nartifact_store: filesystem://<path-to-artifact-store>\ncluster: \n    compute: ray://<ray-host>\n    cdc:    \n        uri: http://<cdc-host>:<cdc-port>\n    vector_search:\n        uri: http://<vector-search-host>:<vector-search-port>\ndatabackend: mysql://<user>:<password>@<host>:<port>/database\n'''        \n"})})}),(0,a.jsx)(o.A,{value:"Oracle",label:"Oracle",default:!0,children:(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"CFG = '''\nartifact_store: filesystem://<path-to-artifact-store>\ncluster: \n    compute: ray://<ray-host>\n    cdc:    \n        uri: http://<cdc-host>:<cdc-port>\n    vector_search:\n        uri: http://<vector-search-host>:<vector-search-port>\ndatabackend: mssql://<user>:<password>@<host>:<port>\n'''        \n"})})}),(0,a.jsx)(o.A,{value:"PostgreSQL",label:"PostgreSQL",default:!0,children:(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"CFG = '''\nartifact_store: filesystem://<path-to-artifact-store>\ncluster: \n    compute: ray://<ray-host>\n    cdc:    \n        uri: http://<cdc-host>:<cdc-port>\n    vector_search:\n        uri: http://<vector-search-host>:<vector-search-port>\ndatabackend: postgres://<user>:<password>@<host>:<port</<database>\n'''        \n"})})}),(0,a.jsx)(o.A,{value:"Snowflake",label:"Snowflake",default:!0,children:(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"CFG = '''\nartifact_store: filesystem://<path-to-artifact-store>\nmetadata_store: sqlite://<path-to-sqlite-db>.db\ncluster: \n    compute: ray://<ray-host>\n    cdc:    \n        uri: http://<cdc-host>:<cdc-port>\n    vector_search:\n        uri: http://<vector-search-host>:<vector-search-port>\ndatabackend: snowflake://<user>:<password>@<account>/<database>\n'''        \n"})})}),(0,a.jsx)(o.A,{value:"Clickhouse",label:"Clickhouse",default:!0,children:(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"CFG = '''\nartifact_store: filesystem://<path-to-artifact-store>\nmetadata_store: sqlite://<path-to-sqlite-db>.db\ncluster: \n    compute: ray://<ray-host>\n    cdc:    \n        uri: http://<cdc-host>:<cdc-port>\n    vector_search:\n        uri: http://<vector-search-host>:<vector-search-port>\ndatabackend: clickhouse://<user>:<password>@<host>:<port>\n'''        \n"})})})]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"with open(os.environ['SUPERDUPERDB_CONFIG'], 'w') as f:\n    f.write(CFG)\n"})}),"\n",(0,a.jsx)(n.h2,{id:"start-your-cluster",children:"Start your cluster"}),"\n",(0,a.jsxs)(n.admonition,{type:"note",children:[(0,a.jsx)(n.p,{children:"Starting a SuperDuperDB cluster is useful in production and model development\nif you want to enable scalable compute, access to the models by multiple users for collaboration,\nmonitoring."}),(0,a.jsx)(n.p,{children:"If you don't need this, then it is simpler to start in development mode."})]}),"\n",(0,a.jsxs)(s.A,{children:[(0,a.jsx)(o.A,{value:"Experimental Cluster",label:"Experimental Cluster",default:!0,children:(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"!python -m superduperdb local-cluster up        \n"})})}),(0,a.jsx)(o.A,{value:"Docker-Compose",label:"Docker-Compose",default:!0,children:(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"!make build_sandbox\n!make testenv_init        \n"})})})]}),"\n",(0,a.jsx)(n.h2,{id:"connect-to-superduperdb",children:"Connect to SuperDuperDB"}),"\n",(0,a.jsx)(n.admonition,{type:"note",children:(0,a.jsx)(n.p,{children:'Note that this is only relevant if you are running SuperDuperDB in development mode.\nOtherwise refer to "Configuring your production system".'})}),"\n",(0,a.jsxs)(s.A,{children:[(0,a.jsx)(o.A,{value:"MongoDB",label:"MongoDB",default:!0,children:(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"from superduperdb import superduper\n\ndb = superduper('mongodb://localhost:27017/documents')        \n"})})}),(0,a.jsx)(o.A,{value:"SQLite",label:"SQLite",default:!0,children:(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"from superduperdb import superduper\ndb = superduper('sqlite://my_db.db')        \n"})})}),(0,a.jsx)(o.A,{value:"MySQL",label:"MySQL",default:!0,children:(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"from superduperdb import superduper\n\nuser = 'superduper'\npassword = 'superduper'\nport = 3306\nhost = 'localhost'\ndatabase = 'test_db'\n\ndb = superduper(f\"mysql://{user}:{password}@{host}:{port}/{database}\")        \n"})})}),(0,a.jsx)(o.A,{value:"Oracle",label:"Oracle",default:!0,children:(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"from superduperdb import superduper\n\nuser = 'sa'\npassword = 'Superduper#1'\nport = 1433\nhost = 'localhost'\n\ndb = superduper(f\"mssql://{user}:{password}@{host}:{port}\")        \n"})})}),(0,a.jsx)(o.A,{value:"PostgreSQL",label:"PostgreSQL",default:!0,children:(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"!pip install psycopg2\nfrom superduperdb import superduper\n\nuser = 'postgres'\npassword = 'postgres'\nport = 5432\nhost = 'localhost'\ndatabase = 'test_db'\ndb_uri = f\"postgres://{user}:{password}@{host}:{port}/{database}\"\n\ndb = superduper(db_uri, metadata_store=db_uri.replace('postgres://', 'postgresql://'))        \n"})})}),(0,a.jsx)(o.A,{value:"Snowflake",label:"Snowflake",default:!0,children:(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'from superduperdb import superduper\n\nuser = "superduperuser"\npassword = "superduperpassword"\naccount = "XXXX-XXXX"  # ORGANIZATIONID-USERID\ndatabase = "FREE_COMPANY_DATASET/PUBLIC"\n\nsnowflake_uri = f"snowflake://{user}:{password}@{account}/{database}"\n\ndb = superduper(\n    snowflake_uri, \n    metadata_store=\'sqlite:///your_database_name.db\',\n)        \n'})})}),(0,a.jsx)(o.A,{value:"Clickhouse",label:"Clickhouse",default:!0,children:(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"from superduperdb import superduper\n\nuser = 'default'\npassword = ''\nport = 8123\nhost = 'localhost'\n\ndb = superduper(f\"clickhouse://{user}:{password}@{host}:{port}\", metadata_store=f'mongomock://meta')        \n"})})}),(0,a.jsx)(o.A,{value:"DuckDB",label:"DuckDB",default:!0,children:(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"from superduperdb import superduper\n\ndb = superduper('duckdb://mydb.duckdb')        \n"})})}),(0,a.jsx)(o.A,{value:"Pandas",label:"Pandas",default:!0,children:(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"from superduperdb import superduper\n\ndb = superduper(['my.csv'], metadata_store=f'mongomock://meta')        \n"})})}),(0,a.jsx)(o.A,{value:"MongoMock",label:"MongoMock",default:!0,children:(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"from superduperdb import superduper\n\ndb = superduper('mongomock:///test_db')        \n"})})})]}),"\n",(0,a.jsx)(n.h2,{id:"get-useful-sample-data",children:"Get useful sample data"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"from superduperdb.backends.ibis import dtype\n\n"})}),"\n",(0,a.jsxs)(s.A,{children:[(0,a.jsx)(o.A,{value:"Text",label:"Text",default:!0,children:(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"!curl -O https://superduperdb-public-demo.s3.amazonaws.com/text.json\nimport json\n\nwith open('text.json', 'r') as f:\n    data = json.load(f)\nsample_datapoint = \"What is mongodb?\"\n\nchunked_model_datatype = dtype('str')        \n"})})}),(0,a.jsx)(o.A,{value:"PDF",label:"PDF",default:!0,children:(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"!curl -O https://superduperdb-public-demo.s3.amazonaws.com/pdfs.zip && unzip -o pdfs.zip\nimport os\n\ndata = [f'pdfs/{x}' for x in os.listdir('./pdfs')]\n\nsample_datapoint = data[-1]\nchunked_model_datatype = dtype('str')        \n"})})}),(0,a.jsx)(o.A,{value:"Image",label:"Image",default:!0,children:(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"!curl -O s3://superduperdb-public-demo/images.zip && unzip images.zip\nimport os\nfrom PIL import Image\n\ndata = [f'images/{x}' for x in os.listdir('./images')]\ndata = [ Image.open(path) for path in data]\nsample_datapoint = data[-1]\n\nfrom superduperdb.ext.pillow import pil_image\nchunked_model_datatype = pil_image        \n"})})}),(0,a.jsx)(o.A,{value:"Video",label:"Video",default:!0,children:(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"!curl -O https://superduperdb-public-demo.s3.amazonaws.com/videos.zip && unzip videos.zip\nimport os\n\ndata = [f'videos/{x}' for x in os.listdir('./videos')]\nsample_datapoint = data[-1]\n\nfrom superduperdb.ext.pillow import pil_image\nchunked_model_datatype = pil_image        \n"})})}),(0,a.jsx)(o.A,{value:"Audio",label:"Audio",default:!0,children:(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"!curl -O https://superduperdb-public-demo.s3.amazonaws.com/audio.zip && unzip audio.zip\nimport os\n\ndata = [f'audios/{x}' for x in os.listdir('./audios')]\nsample_datapoint = data[-1]\nchunked_model_datatype = dtype('str')        \n"})})})]}),"\n",(0,a.jsx)(n.h2,{id:"create-datatype",children:"Create datatype"}),"\n",(0,a.jsxs)(n.p,{children:['Data types such as "text" or "integer" which are natively support by your ',(0,a.jsx)(n.code,{children:"db.databackend"})," don't need a datatype."]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"datatype = None\n"})}),"\n",(0,a.jsx)(n.p,{children:"Otherwise do one of the following:"}),"\n",(0,a.jsxs)(s.A,{children:[(0,a.jsx)(o.A,{value:"PDF",label:"PDF",default:!0,children:(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"!pip install PyPDF2\nfrom superduperdb import DataType\nfrom superduperdb.components.datatype import File\n\ndatatype = DataType('pdf', encodable='file')        \n"})})}),(0,a.jsx)(o.A,{value:"Text",label:"Text",default:!0,children:(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"datatype = 'str'        \n"})})}),(0,a.jsx)(o.A,{value:"Image",label:"Image",default:!0,children:(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"from superduperdb.ext.pillow import pil_image\nimport PIL.Image\n\ndatatype = pil_image        \n"})})}),(0,a.jsx)(o.A,{value:"Audio",label:"Audio",default:!0,children:(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"from superduperdb.ext.numpy import array\nfrom superduperdb import DataType\nimport scipy.io.wavfile\nimport io\n\n\ndef encoder(data):\n    buffer = io.BytesIO()\n    fs = data[0]\n    content = data[1]\n    scipy.io.wavfile.write(buffer, fs, content)\n    return buffer.getvalue()\n\n\ndef decoder(data):\n    buffer = io.BytesIO(data)\n    content = scipy.io.wavfile.read(buffer)\n    return content\n\n\ndatatype = DataType(\n    'wav',\n    encoder=encoder,\n    decoder=decoder,\n    encodable='artifact',\n)        \n"})})}),(0,a.jsx)(o.A,{value:"Video",label:"Video",default:!0,children:(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"from superduperdb import DataType\n\n# Create an instance of the Encoder with the identifier 'video_on_file' and load_hybrid set to False\ndatatype = DataType(\n    identifier='video_on_file',\n    encodable='artifact',\n)        \n"})})})]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"from superduperdb import DataType\nif datatype and isinstance(datatype, DataType):\n    db.apply(datatype)\n"})}),"\n",(0,a.jsx)(n.h2,{id:"setup-tables-or-collections",children:"Setup tables or collections"}),"\n",(0,a.jsxs)(s.A,{children:[(0,a.jsx)(o.A,{value:"MongoDB",label:"MongoDB",default:!0,children:(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"# Note this is an optional step for MongoDB\n# Users can also work directly with `DataType` if they want to add\n# custom data\nfrom superduperdb import Schema, DataType\nfrom superduperdb.backends.mongodb import Collection\n\ntable_or_collection = Collection('documents')\nUSE_SCHEMA = False\n\nif USE_SCHEMA and isinstance(datatype, DataType):\n    schema = Schema(fields={'x': datatype})\n    db.apply(schema)        \n"})})}),(0,a.jsx)(o.A,{value:"SQL",label:"SQL",default:!0,children:(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'from superduperdb.backends.ibis import Table\nfrom superduperdb import Schema, DataType\nfrom superduperdb.backends.ibis.field_types import dtype\n\ndatatype = "str"\n\nif isinstance(datatype, DataType):\n    schema = Schema(identifier="schema", fields={"id": dtype("str"), "x": datatype})\nelse:\n    schema = Schema(\n        identifier="schema", fields={"id": dtype("str"), "x": dtype(datatype)}\n    )\n\ntable_or_collection = Table(\'documents\', schema=schema)\n\ndb.apply(table_or_collection)        \n'})})})]}),"\n",(0,a.jsx)(n.h2,{id:"insert-data",children:"Insert data"}),"\n",(0,a.jsxs)(n.p,{children:["In order to create data, we need to create a ",(0,a.jsx)(n.code,{children:"Schema"})," for encoding our special ",(0,a.jsx)(n.code,{children:"Datatype"})," column(s) in the databackend."]}),"\n",(0,a.jsxs)(s.A,{children:[(0,a.jsx)(o.A,{value:"MongoDB",label:"MongoDB",default:!0,children:(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"from superduperdb import Document, DataType\n\ndef do_insert(data, schema = None):\n    \n    if schema is None and (datatype is None or isinstance(datatype, str)):\n        data = [Document({'x': x['x'], 'y': x['y']}) if isinstance(x, dict) and 'x' in x and 'y' in x else Document({'x': x}) for x in data]\n        db.execute(table_or_collection.insert_many(data))\n    elif schema is None and datatype is not None and isinstance(datatype, DataType):\n        data = [Document({'x': datatype(x['x']), 'y': x['y']}) if isinstance(x, dict) and 'x' in x and 'y' in x else Document({'x': datatype(x)}) for x in data]\n        db.execute(table_or_collection.insert_many(data))\n    else:\n        data = [Document({'x': x['x'], 'y': x['y']}) if isinstance(x, dict) and 'x' in x and 'y' in x else Document({'x': x}) for x in data]\n        db.execute(table_or_collection.insert_many(data, schema=schema))\n\n"})})}),(0,a.jsx)(o.A,{value:"SQL",label:"SQL",default:!0,children:(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"from superduperdb import Document\n\ndef do_insert(data):\n    db.execute(table_or_collection.insert([Document({'id': str(idx), 'x': x['x'], 'y': x['y']}) if isinstance(x, dict) and 'x' in x and 'y' in x else Document({'id': str(idx), 'x': x}) for idx, x in enumerate(data)]))\n\n"})})})]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"do_insert(data[:-len(data) // 4])\n"})}),"\n",(0,a.jsx)(n.h4,{id:"define-the-embedding-model-datatype",children:"Define the embedding model datatype"}),"\n",(0,a.jsxs)(s.A,{children:[(0,a.jsx)(o.A,{value:"SQL",label:"SQL",default:!0,children:(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"from superduperdb.components.vector_index import sqlvector\nget_chunking_datatype = lambda shape: sqlvector(shape=(shape,))        \n"})})}),(0,a.jsx)(o.A,{value:"MongoDB",label:"MongoDB",default:!0,children:(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"from superduperdb.components.vector_index import vector\nget_chunking_datatype = lambda shape: vector(shape=(shape,))        \n"})})})]}),"\n",(0,a.jsx)(n.h2,{id:"build-simple-select-queries",children:"Build simple select queries"}),"\n",(0,a.jsxs)(s.A,{children:[(0,a.jsx)(o.A,{value:"MongoDB",label:"MongoDB",default:!0,children:(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"\nselect = table_or_collection.find({})        \n"})})}),(0,a.jsx)(o.A,{value:"SQL",label:"SQL",default:!0,children:(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"\nselect = table_or_collection.to_query()        \n"})})})]}),"\n",(0,a.jsx)(n.h2,{id:"create-model-output-type",children:"Create Model Output Type"}),"\n",(0,a.jsxs)(s.A,{children:[(0,a.jsx)(o.A,{value:"MongoDB",label:"MongoDB",default:!0,children:(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"chunked_model_datatype = None        \n"})})}),(0,a.jsx)(o.A,{value:"SQL",label:"SQL",default:!0,children:(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"from superduperdb.backends.ibis.field_types import dtype\nchunked_model_datatype = dtype('str')        \n"})})})]}),"\n",(0,a.jsx)(n.h2,{id:"apply-a-chunker-for-search",children:"Apply a chunker for search"}),"\n",(0,a.jsx)(n.admonition,{type:"note",children:(0,a.jsxs)(n.p,{children:["Note that applying a chunker is ",(0,a.jsx)(n.em,{children:(0,a.jsx)(n.strong,{children:"not"})})," mandatory for search.\nIf your data is already chunked (e.g. short text snippets or audio) or if you\nare searching through something like images, which can't be chunked, then this\nwon't be necessary."]})}),"\n",(0,a.jsxs)(s.A,{children:[(0,a.jsx)(o.A,{value:"Text",label:"Text",default:!0,children:(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"from superduperdb import objectmodel\n\nCHUNK_SIZE = 200\n\n@objectmodel(flatten=True, model_update_kwargs={'document_embedded': False}, datatype=chunked_model_datatype)\ndef chunker(text):\n    text = text.split()\n    chunks = [' '.join(text[i:i + CHUNK_SIZE]) for i in range(0, len(text), CHUNK_SIZE)]\n    return chunks        \n"})})}),(0,a.jsx)(o.A,{value:"PDF",label:"PDF",default:!0,children:(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"!pip install -q \"unstructured[pdf]\"\nfrom superduperdb import objectmodel\nfrom unstructured.partition.pdf import partition_pdf\nimport PyPDF2\n\nCHUNK_SIZE = 500\n\n@objectmodel(flatten=True, model_update_kwargs={'document_embedded': False}, datatype=chunked_model_datatype)\ndef chunker(pdf_file):\n    elements = partition_pdf(pdf_file)\n    text = '\\n'.join([e.text for e in elements])\n    chunks = [text[i:i + CHUNK_SIZE] for i in range(0, len(text), CHUNK_SIZE)]\n    return chunks        \n"})})}),(0,a.jsx)(o.A,{value:"Video",label:"Video",default:!0,children:(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"!pip install opencv-python\nimport cv2\nimport tqdm\nfrom PIL import Image\nfrom superduperdb.ext.pillow import pil_image\nfrom superduperdb import objectmodel, Schema\n\n\n@objectmodel(\n    flatten=True,\n    model_update_kwargs={'document_embedded': False},\n    output_schema=Schema(identifier='output-schema', fields={'image': pil_image}),\n)\ndef chunker(video_file):\n    # Set the sampling frequency for frames\n    sample_freq = 10\n    \n    # Open the video file using OpenCV\n    cap = cv2.VideoCapture(video_file)\n    \n    # Initialize variables\n    frame_count = 0\n    fps = cap.get(cv2.CAP_PROP_FPS)\n    extracted_frames = []\n    progress = tqdm.tqdm()\n\n    # Iterate through video frames\n    while True:\n        ret, frame = cap.read()\n        if not ret:\n            break\n        \n        # Get the current timestamp based on frame count and FPS\n        current_timestamp = frame_count // fps\n        \n        # Sample frames based on the specified frequency\n        if frame_count % sample_freq == 0:\n            extracted_frames.append({\n                'image': Image.fromarray(frame[:,:,::-1]),  # Convert BGR to RGB\n                'current_timestamp': current_timestamp,\n            })\n        frame_count += 1\n        progress.update(1)\n    \n    # Release resources\n    cap.release()\n    cv2.destroyAllWindows()\n    \n    # Return the list of extracted frames\n    return extracted_frames        \n"})})}),(0,a.jsx)(o.A,{value:"Audio",label:"Audio",default:!0,children:(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"from superduperdb import objectmodel, Schema\n\nCHUNK_SIZE = 10  # in seconds\n\n@objectmodel(\n    flatten=True,\n    model_update_kwargs={'document_embedded': False},\n    output_schema=Schema(identifier='output-schema', fields={'audio': datatype}),\n)\ndef chunker(audio):\n    chunks = []\n    for i in range(0, len(audio), CHUNK_SIZE):\n        chunks.append(audio[1][i: i + CHUNK_SIZE])\n    return [(audio[0], chunk) for chunk in chunks]        \n"})})})]}),"\n",(0,a.jsxs)(n.p,{children:["Now we apply this chunker to the data by wrapping the chunker in ",(0,a.jsx)(n.code,{children:"Listener"}),":"]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"from superduperdb import Listener\n\nupstream_listener = Listener(\n    model=chunker,\n    select=select,\n    key='x',\n)\n\ndb.apply(upstream_listener)\n"})}),"\n",(0,a.jsx)(n.h2,{id:"build-multimodal-embedding-models",children:"Build multimodal embedding models"}),"\n",(0,a.jsxs)(n.p,{children:["Some embedding models such as ",(0,a.jsx)(n.a,{href:"https://github.com/openai/CLIP",children:"CLIP"})," come in pairs of ",(0,a.jsx)(n.code,{children:"model"})," and ",(0,a.jsx)(n.code,{children:"compatible_model"}),".\nOtherwise:"]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"compatible_model = None\n"})}),"\n",(0,a.jsxs)(s.A,{children:[(0,a.jsx)(o.A,{value:"Text",label:"Text",default:!0,children:(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"from superduperdb.ext.sentence_transformers import SentenceTransformer\n\nif not get_chunking_datatype:\n    model_dtype =  vector(shape=(384,))\nelse:\n    model_dtype = get_chunking_datatype(384)\n\n# Load the pre-trained sentence transformer model\nmodel = SentenceTransformer(\n    identifier='all-MiniLM-L6-v2',\n    postprocess=lambda x: x.tolist(),\n    datatype=model_dtype,\n)        \n"})})}),(0,a.jsx)(o.A,{value:"Image",label:"Image",default:!0,children:(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"from torchvision import transforms\nimport torch\nimport torch.nn as nn\nimport torchvision.models as models\n\nimport warnings\n\n# Import custom modules\nfrom superduperdb.ext.torch import TorchModel, tensor\n\n# Define a series of image transformations using torchvision.transforms.Compose\nt = transforms.Compose([\n    transforms.Resize((224, 224)),   # Resize the input image to 224x224 pixels (must same as here)\n    transforms.CenterCrop((224, 224)),  # Perform a center crop on the resized image\n    transforms.ToTensor(),  # Convert the image to a PyTorch tensor\n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])  # Normalize the tensor with specified mean and standard deviation\n])\n\n# Define a preprocess function that applies the defined transformations to an input image\ndef preprocess(x):\n    try:\n        return t(x)\n    except Exception as e:\n        # If an exception occurs during preprocessing, issue a warning and return a tensor of zeros\n        warnings.warn(str(e))\n        return torch.zeros(3, 224, 224)\n\n# Load the pre-trained ResNet-50 model from torchvision\nresnet50 = models.resnet50(pretrained=True)\n\n# Extract all layers of the ResNet-50 model except the last one\nmodules = list(resnet50.children())[:-1]\nresnet50 = nn.Sequential(*modules)\n\n# Create a TorchModel instance with the ResNet-50 model, preprocessing function, and postprocessing lambda\nmodel = TorchModel(\n    identifier='resnet50',\n    preprocess=preprocess,\n    object=resnet50,\n    postprocess=lambda x: x[:, 0, 0],  # Postprocess by extracting the top-left element of the output tensor\n    datatype=tensor(torch.float, shape=(2048,))  # Specify the encoder configuration\n)        \n"})})}),(0,a.jsx)(o.A,{value:"Text+Image",label:"Text+Image",default:!0,children:(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"import clip\nfrom superduperdb import vector\nfrom superduperdb.ext.torch import TorchModel\n\n# Load the CLIP model and obtain the preprocessing function\nmodel, preprocess = clip.load(\"RN50\", device='cpu')\n\n# Define a vector with shape (1024,)\n\nif not get_chunking_datatype:\n    e =  vector(shape=(1024,))\nelse:\n    e = get_chunking_datatype(1024)\n\n\n# Create a TorchModel for text encoding\ncompatible_model = TorchModel(\n    identifier='clip_text', # Unique identifier for the model\n    object=model, # CLIP model\n    preprocess=lambda x: clip.tokenize(x)[0],  # Model input preprocessing using CLIP \n    postprocess=lambda x: x.tolist(), # Convert the model output to a list\n    datatype=e,  # Vector encoder with shape (1024,)\n    forward_method='encode_text', # Use the 'encode_text' method for forward pass \n)\n\n# Create a TorchModel for visual encoding\nmodel = TorchModel(\n    identifier='clip_image',  # Unique identifier for the model\n    object=model.visual,  # Visual part of the CLIP model    \n    preprocess=preprocess, # Visual preprocessing using CLIP\n    postprocess=lambda x: x.tolist(), # Convert the output to a list \n    datatype=e, # Vector encoder with shape (1024,)\n)        \n"})})}),(0,a.jsx)(o.A,{value:"Audio",label:"Audio",default:!0,children:(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"!pip install librosa\nimport librosa\nimport numpy as np\nfrom superduperdb import ObjectModel\nfrom superduperdb import vector\n\ndef audio_embedding(audio_file):\n    # Load the audio file\n    MAX_SIZE= 10000\n    y, sr = librosa.load(audio_file)\n    y = y[:MAX_SIZE]\n    mfccs = librosa.feature.mfcc(y=y, sr=44000, n_mfcc=1)\n    mfccs =  mfccs.squeeze().tolist()\n    return mfccs\n\nif not get_chunking_datatype:\n    e =  vector(shape=(1000,))\nelse:\n    e = get_chunking_datatype(1000)\n\nmodel= ObjectModel(identifier='my-model-audio', object=audio_embedding, datatype=e)        \n"})})})]}),"\n",(0,a.jsx)(n.h2,{id:"select-outputs-of-upstream-listener",children:"Select outputs of upstream listener"}),"\n",(0,a.jsx)(n.admonition,{type:"note",children:(0,a.jsx)(n.p,{children:"This is useful if you have performed a first step, such as pre-computing\nfeatures, or chunking your data. You can use this query to\noperate on those outputs."})}),"\n",(0,a.jsxs)(s.A,{children:[(0,a.jsx)(o.A,{value:"MongoDB",label:"MongoDB",default:!0,children:(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"from superduperdb.backends.mongodb import Collection\n\nindexing_key = upstream_listener.outputs\nselect = Collection(upstream_listener.outputs).find()        \n"})})}),(0,a.jsx)(o.A,{value:"SQL",label:"SQL",default:!0,children:(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'indexing_key = upstream_listener.outputs_key\nselect = db.load("table", upstream_listener.outputs).to_query()        \n'})})})]}),"\n",(0,a.jsx)(n.p,{children:"Depending on whether we have chunked the data,\nthe indexing key will be different:"}),"\n",(0,a.jsxs)(s.A,{children:[(0,a.jsx)(o.A,{value:"Chunked Search",label:"Chunked Search",default:!0,children:(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"compatible_key = None\nif compatible_model:\n    compatible_key = 'y'        \n"})})}),(0,a.jsx)(o.A,{value:"Un-chunked Search",label:"Un-chunked Search",default:!0,children:(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"indexing_key = 'x'\ncompatible_key = None\nif compatible_model:\n    compatible_key = 'y'        \n"})})})]}),"\n",(0,a.jsx)(n.h2,{id:"create-vector-index",children:"Create vector-index"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"vector_index_name = 'my-vector-index'\n"})}),"\n",(0,a.jsxs)(s.A,{children:[(0,a.jsx)(o.A,{value:"1-Modality",label:"1-Modality",default:!0,children:(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"from superduperdb import VectorIndex, Listener\n\njobs, _ = db.add(\n    VectorIndex(\n        vector_index_name,\n        indexing_listener=Listener(\n            key=indexing_key,      # the `Document` key `model` should ingest to create embedding\n            select=select,       # a `Select` query telling which data to search over\n            model=model,         # a `_Predictor` how to convert data to embeddings\n        )\n    )\n)        \n"})})}),(0,a.jsx)(o.A,{value:"2-Modalities",label:"2-Modalities",default:!0,children:(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"from superduperdb import VectorIndex, Listener\n\njobs, _ = db.add(\n    VectorIndex(\n        vector_index_name,\n        indexing_listener=Listener(\n            key=indexing_key,      # the `Document` key `model` should ingest to create embedding\n            select=select,       # a `Select` query telling which data to search over\n            model=model,         # a `_Predictor` how to convert data to embeddings\n        ),\n        compatible_listener=Listener(\n            key=compatible_key,      # the `Document` key `model` should ingest to create embedding\n            model=compatible_model,         # a `_Predictor` how to convert data to embeddings\n            active=False,\n            select=None,\n        )\n    )\n)        \n"})})})]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"query_table_or_collection = select.table_or_collection\n"})}),"\n",(0,a.jsx)(n.h2,{id:"perform-a-vector-search",children:"Perform a vector search"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"from superduperdb import Document\n\ndef get_sample_item(key, sample_datapoint, datatype=None):\n    if not isinstance(datatype, DataType):\n        item = Document({key: sample_datapoint})\n    else:\n        item = Document({key: datatype(sample_datapoint)})\n\n    return item\n\nif compatible_key:\n    item = get_sample_item(compatible_key, sample_datapoint, None)\nelse:\n    item = get_sample_item(indexing_key, sample_datapoint, datatype=datatype)\n"})}),"\n",(0,a.jsx)(n.p,{children:"Once we have this search target, we can execute a search as follows:"}),"\n",(0,a.jsxs)(s.A,{children:[(0,a.jsx)(o.A,{value:"MongoDB",label:"MongoDB",default:!0,children:(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"select = query_table_or_collection.like(item, vector_index=vector_index_name, n=10).find()        \n"})})}),(0,a.jsx)(o.A,{value:"SQL",label:"SQL",default:!0,children:(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"select = query_table_or_collection.like(item, vector_index=vector_index_name, n=10).limit(10)        \n"})})})]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"results = db.execute(select)\n"})}),"\n",(0,a.jsx)(n.h2,{id:"visualize-results",children:"Visualize Results"}),"\n",(0,a.jsxs)(s.A,{children:[(0,a.jsx)(o.A,{value:"Text",label:"Text",default:!0,children:(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"from IPython.display import Markdown, display\n\ndef visualize(item, source):\n    display(Markdown(item))\n    \ndef show(results, output_key, get_original_callable=None):\n    for result in results:\n        source = None\n        if '_source' in result:\n            \n            source = get_original_callable(result['_source'])\n        visualize(result[output_key], source)        \n"})})}),(0,a.jsx)(o.A,{value:"Image",label:"Image",default:!0,children:(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"from IPython.display import display\n\ndef visualize(item, source):\n    display(item)        # item is a PIL.Image\n\ndef show(results, output_key, get_original_callable=None):\n    for result in results:\n        source = None\n        if '_source' in result:\n            source = get_original_callable(result['_source'])\n        visualize(result[output_key], source)        \n"})})}),(0,a.jsx)(o.A,{value:"Audio",label:"Audio",default:!0,children:(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"from IPython.display import Audio, display\n\ndef visualize(item, source):\n    display(Audio(item[1], fs=item[0]))\n\ndef show(results, output_key, get_original_callable=None):\n    for result in results:\n        source = None\n        if '_source' in result:\n            \n            source = get_original_callable(result['_source'])\n        visualize(result[output_key], source)        \n"})})}),(0,a.jsx)(o.A,{value:"PDF",label:"PDF",default:!0,children:(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"from IPython.display import IFrame, display\n\ndef visualize(item, source):\n    display(item)\n\n\ndef show(results, output_key, get_original_callable=None):\n    for result in results:\n        source = None\n        if '_source' in result:\n            \n            source = get_original_callable(result['_source'])\n        visualize(result[output_key], source)        \n"})})}),(0,a.jsx)(o.A,{value:"Video",label:"Video",default:!0,children:(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'from IPython.display import display, HTML\n\ndef visualize(uri, source):\n    timestamp = source    # increment to the frame you want to start at\n    \n    # Create HTML code for the video player with a specified source and controls\n    video_html = f"""\n    <video width="640" height="480" controls>\n        <source src="{uri}" type="video/mp4">\n    </video>\n    <script>\n        // Get the video element\n        var video = document.querySelector(\'video\');\n        \n        // Set the current time of the video to the specified timestamp\n        video.currentTime = {timestamp};\n        \n        // Play the video automatically\n        video.play();\n    <\/script>\n    """\n    \n    display(HTML(video_html))\n\n\ndef show(results, output_key, get_original_callable=None):\n    # show only the first video\n    for result in results:\n        result = result[output_key]\n        timestamp = result[\'current_timestamp\']\n        source = result[\'_source\']\n        uri = get_original_callable(source)[\'x\']\n        visualize(uri, timestamp)\n        break        \n'})})})]}),"\n",(0,a.jsx)(n.p,{children:"If your use-case involved chunking, you will want to be able to recover original rows/ documents,\nafter getting the result of a vector-search:"}),"\n",(0,a.jsxs)(s.A,{children:[(0,a.jsx)(o.A,{value:"MongoDB",label:"MongoDB",default:!0,children:(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"def get_original(_source):\n    return db.execute(table_or_collection.find_one({'_id': _source}))\n    \nvisualization_key = upstream_listener.outputs        \n"})})}),(0,a.jsx)(o.A,{value:"SQL",label:"SQL",default:!0,children:(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"def get_original(_source):\n    return next(db.execute(table_or_collection.select_using_ids([_source])))\n    \nvisualization_key = indexing_key        \n"})})})]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"show(results, visualization_key, get_original)\n"})}),"\n",(0,a.jsx)(n.h2,{id:"check-the-system-stays-updated",children:"Check the system stays updated"}),"\n",(0,a.jsxs)(s.A,{children:[(0,a.jsx)(o.A,{value:"Development",label:"Development",default:!0,children:(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"\ndo_insert(data[-len(data) // 4:])        \n"})})}),(0,a.jsx)(o.A,{value:"Cluster",label:"Cluster",default:!0,children:(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"\n# As an example with MongoDB, we show that inserting to/ updating the DB with a different client (potentially from different source)\n# still means that the system stays up-to-date. This should work with any Cluster mode compatible DB (see \"Configuring your production system\")\n\ncollection = pymongo.MongoClient('mongodb://<mongo-host>:/27017/<database>')['<database>'].documents\ncollection.insert_many([{'x': x} for x in data[-len(data) // 4:])        \n"})})})]}),"\n",(0,a.jsx)(l.A,{filename:"multimodal_vector_search.md"})]})}function m(e={}){const{wrapper:n}={...(0,r.R)(),...e.components};return n?(0,a.jsx)(n,{...e,children:(0,a.jsx)(h,{...e})}):h(e)}},94:(e,n,t)=>{t.d(n,{A:()=>o});var a=t(6540);const r=e=>{const n=Array.from(document.querySelectorAll('.tabs > li[role="tab"]')).filter((e=>"true"===e.getAttribute("aria-selected"))).map((e=>e.textContent.trim()));console.log("About to process filename:",e),console.log("Selected tabs:",n);const t=`_${e.replace(/\.md$/,".ipynb")}`,a=encodeURIComponent(t);fetch(`https://build-use-cases-sddb.replit.app/build_notebook?usecase_path=.%2Fuse_cases%2F${a}`,{method:"POST",headers:{"Content-Type":"application/json",Accept:"application/json"},body:JSON.stringify(n)}).then((e=>e.blob())).then((e=>{const n=window.URL.createObjectURL(e),a=document.createElement("a");a.style.display="none",a.href=n,a.download=t,document.body.appendChild(a),a.click(),window.URL.revokeObjectURL(n),alert("Your file has downloaded!")})).catch((()=>alert("There was an error."))),console.log("Sending JSON payload:",JSON.stringify(n))};var s=t(4848);const o=e=>{let{filename:n}=e;if(!n)return console.error("Filename is not provided or invalid."),null;const[t,o]=(0,a.useState)(!1),l={padding:"10px",borderRadius:"10px",border:"0",color:"#000",backgroundColor:"#C4F800",fontWeight:"bold",cursor:"pointer"};return(0,s.jsx)("button",{style:t?{...l,backgroundColor:"#B0E000"}:l,onMouseEnter:()=>o(!0),onMouseLeave:()=>o(!1),onClick:()=>r(n),children:"Generate notebook from all selected tabs"})}},7227:(e,n,t)=>{t.d(n,{A:()=>o});t(6540);var a=t(870);const r={tabItem:"tabItem_Ymn6"};var s=t(4848);function o(e){let{children:n,hidden:t,className:o}=e;return(0,s.jsx)("div",{role:"tabpanel",className:(0,a.A)(r.tabItem,o),hidden:t,children:n})}},9489:(e,n,t)=>{t.d(n,{A:()=>v});var a=t(6540),r=t(870),s=t(4245),o=t(6347),l=t(6494),d=t(2814),i=t(5167),c=t(1269);function u(e){return a.Children.toArray(e).filter((e=>"\n"!==e)).map((e=>{if(!e||(0,a.isValidElement)(e)&&function(e){const{props:n}=e;return!!n&&"object"==typeof n&&"value"in n}(e))return e;throw new Error(`Docusaurus error: Bad <Tabs> child <${"string"==typeof e.type?e.type:e.type.name}>: all children of the <Tabs> component should be <TabItem>, and every <TabItem> should have a unique "value" prop.`)}))?.filter(Boolean)??[]}function p(e){const{values:n,children:t}=e;return(0,a.useMemo)((()=>{const e=n??function(e){return u(e).map((e=>{let{props:{value:n,label:t,attributes:a,default:r}}=e;return{value:n,label:t,attributes:a,default:r}}))}(t);return function(e){const n=(0,i.X)(e,((e,n)=>e.value===n.value));if(n.length>0)throw new Error(`Docusaurus error: Duplicate values "${n.map((e=>e.value)).join(", ")}" found in <Tabs>. Every value needs to be unique.`)}(e),e}),[n,t])}function h(e){let{value:n,tabValues:t}=e;return t.some((e=>e.value===n))}function m(e){let{queryString:n=!1,groupId:t}=e;const r=(0,o.W6)(),s=function(e){let{queryString:n=!1,groupId:t}=e;if("string"==typeof n)return n;if(!1===n)return null;if(!0===n&&!t)throw new Error('Docusaurus error: The <Tabs> component groupId prop is required if queryString=true, because this value is used as the search param name. You can also provide an explicit value such as queryString="my-search-param".');return t??null}({queryString:n,groupId:t});return[(0,d.aZ)(s),(0,a.useCallback)((e=>{if(!s)return;const n=new URLSearchParams(r.location.search);n.set(s,e),r.replace({...r.location,search:n.toString()})}),[s,r])]}function f(e){const{defaultValue:n,queryString:t=!1,groupId:r}=e,s=p(e),[o,d]=(0,a.useState)((()=>function(e){let{defaultValue:n,tabValues:t}=e;if(0===t.length)throw new Error("Docusaurus error: the <Tabs> component requires at least one <TabItem> children component");if(n){if(!h({value:n,tabValues:t}))throw new Error(`Docusaurus error: The <Tabs> has a defaultValue "${n}" but none of its children has the corresponding value. Available values are: ${t.map((e=>e.value)).join(", ")}. If you intend to show no default tab, use defaultValue={null} instead.`);return n}const a=t.find((e=>e.default))??t[0];if(!a)throw new Error("Unexpected error: 0 tabValues");return a.value}({defaultValue:n,tabValues:s}))),[i,u]=m({queryString:t,groupId:r}),[f,x]=function(e){let{groupId:n}=e;const t=function(e){return e?`docusaurus.tab.${e}`:null}(n),[r,s]=(0,c.Dv)(t);return[r,(0,a.useCallback)((e=>{t&&s.set(e)}),[t,s])]}({groupId:r}),y=(()=>{const e=i??f;return h({value:e,tabValues:s})?e:null})();(0,l.A)((()=>{y&&d(y)}),[y]);return{selectedValue:o,selectValue:(0,a.useCallback)((e=>{if(!h({value:e,tabValues:s}))throw new Error(`Can't select invalid tab value=${e}`);d(e),u(e),x(e)}),[u,x,s]),tabValues:s}}var x=t(1062);const y={tabList:"tabList__CuJ",tabItem:"tabItem_LNqP"};var g=t(4848);function b(e){let{className:n,block:t,selectedValue:a,selectValue:o,tabValues:l}=e;const d=[],{blockElementScrollPositionUntilNextRender:i}=(0,s.a_)(),c=e=>{const n=e.currentTarget,t=d.indexOf(n),r=l[t].value;r!==a&&(i(n),o(r))},u=e=>{let n=null;switch(e.key){case"Enter":c(e);break;case"ArrowRight":{const t=d.indexOf(e.currentTarget)+1;n=d[t]??d[0];break}case"ArrowLeft":{const t=d.indexOf(e.currentTarget)-1;n=d[t]??d[d.length-1];break}}n?.focus()};return(0,g.jsx)("ul",{role:"tablist","aria-orientation":"horizontal",className:(0,r.A)("tabs",{"tabs--block":t},n),children:l.map((e=>{let{value:n,label:t,attributes:s}=e;return(0,g.jsx)("li",{role:"tab",tabIndex:a===n?0:-1,"aria-selected":a===n,ref:e=>d.push(e),onKeyDown:u,onClick:c,...s,className:(0,r.A)("tabs__item",y.tabItem,s?.className,{"tabs__item--active":a===n}),children:t??n},n)}))})}function _(e){let{lazy:n,children:t,selectedValue:r}=e;const s=(Array.isArray(t)?t:[t]).filter(Boolean);if(n){const e=s.find((e=>e.props.value===r));return e?(0,a.cloneElement)(e,{className:"margin-top--md"}):null}return(0,g.jsx)("div",{className:"margin-top--md",children:s.map(((e,n)=>(0,a.cloneElement)(e,{key:n,hidden:e.props.value!==r})))})}function j(e){const n=f(e);return(0,g.jsxs)("div",{className:(0,r.A)("tabs-container",y.tabList),children:[(0,g.jsx)(b,{...e,...n}),(0,g.jsx)(_,{...e,...n})]})}function v(e){const n=(0,x.A)();return(0,g.jsx)(j,{...e,children:u(e.children)},String(n))}},8453:(e,n,t)=>{t.d(n,{R:()=>o,x:()=>l});var a=t(6540);const r={},s=a.createContext(r);function o(e){const n=a.useContext(s);return a.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function l(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:o(e.components),a.createElement(s.Provider,{value:n},e.children)}}}]);